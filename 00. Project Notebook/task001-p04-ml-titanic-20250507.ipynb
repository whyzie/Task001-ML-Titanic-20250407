{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":239153150,"sourceType":"kernelVersion"},{"sourceId":379622,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":313765,"modelId":334180}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:38:28.759234Z","iopub.execute_input":"2025-05-12T23:38:28.759480Z","iopub.status.idle":"2025-05-12T23:38:29.071476Z","shell.execute_reply.started":"2025-05-12T23:38:28.759460Z","shell.execute_reply":"2025-05-12T23:38:29.067485Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_rf_1.joblib\n/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_rf_10.joblib\n/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_rf_3.joblib\n/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_rf_11.joblib\n/kaggle/input/task001-p01-ml-titanic-20250407/all_data_df.csv\n/kaggle/input/task001-p01-ml-titanic-20250407/__results__.html\n/kaggle/input/task001-p01-ml-titanic-20250407/train_df_1.csv\n/kaggle/input/task001-p01-ml-titanic-20250407/__notebook__.ipynb\n/kaggle/input/task001-p01-ml-titanic-20250407/__output__.json\n/kaggle/input/task001-p01-ml-titanic-20250407/custom.css\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___196_2.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___180_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___169_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___195_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___211_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___121_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___162_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___181_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___196_4.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___196_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___179_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___163_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___191_3.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___213_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___152_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___117_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___66_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___214_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___169_2.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___193_3.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___193_2.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___205_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___199_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___191_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___193_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___196_3.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___167_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___102_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___158_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___204_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___191_4.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___212_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___123_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___196_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___193_4.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___192_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___62_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___105_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___148_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___23_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___109_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___165_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___118_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___97_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___50_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___194_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___172_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___150_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___202_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___193_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___191_2.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___210_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___203_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___191_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___98_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___166_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___45_1.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___153_0.png\n/kaggle/input/task001-p01-ml-titanic-20250407/__results___files/__results___160_0.png\n/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"<div>\n    <h1> <a id=\"Obj1\">üéØObjectives</a></h1>\n    <h3 style=\"text-align:justify; font-family: Calibri\">Build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc). <br></h3>  \n  \n<p style = \"font-family: Arial; font-size: 14px\">Note: This project's dataset was created for pedagogical purposes and may not be indicative of the task .</p>\n<hr>","metadata":{}},{"cell_type":"markdown","source":"## **Objectives**\n<a id=\"Objectives\"></a>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Note:</b><p style = \"font-family:Verdana; font-size:14px\">We must maintain objectivity when analyzing the data to gain valuable insights. This involves collecting, fact-checking, and challenging the data and other sources. Adopting a Genchi Genbutsu approach, which involves go-seeing for yourself or discussing with subject matter experts, allows us to delve into the data to gain firsthand understanding.</p>\n    <p>Data should adhere to the <b>COV-FAST</b> principles: Clear, Objective, Valuable, Focused, Agile, Scientific, and Time-bound and Trustworthiness.</p>\n</div>\n    <h3>Framework and methodologies</h3>\n     A <b>methodology</b> offers <b>specific steps</b> for completing a project, while a <b>framework</b> provides broader guidance on tools, resources, and workflow processes. As an experienced Green Belt Lean Six Sigma professional, the methodology that I often use is DMAIC. I use PACE as a framework as I found it similar to <b>Knowledge Discovery in Databases (KDD)</b>. Both <b>PACE</b> and <b>KDD</b> aim to guide structured data projects. <b>PACE</b> specifically focuses on machine learning projects, whereas <b>KDD</b> covers a broader range of data discovery techniques.\n     \n<h3>Data analysis PACE steps:</h3>\n   <ol style=\"font-family:Verdana; font-size:16px\">\n    <li><img style=\"float:left\" src=\"https://i.imgur.com/gIne5bH.png\" width=\"50\"> Plan/Prepare - import the relevant libraries and data</li> \n    <blockquote>\n    <ol>Align project with business needs, requirements and contraints. Select an approriate machine learning model based on the problem and business context. KDD: Selection, and Data Wrangling (Pre-processing and Transformation).\n    </ol>\n    </blockquote>\n        <li><img style=\"float:left\" src=\"https://i.imgur.com/rb8V6X5.png\" width=\"50\">Analyze - EDA</li>\n    <blockquote>\n    <ol> Understanding data for accurate predictions, focus on the response variable (what the model predicts) and leverage exploratory data analysis to uncover patterns and address irregularities. KDD: Data Mining.\n     </ol>\n    </blockquote>\n    <li><img style=\"float:left\" src=\"https://i.imgur.com/J4M3HKM.png\" width=\"50\">Construct - model </li>\n    <blockquote>\n    <ol>Construct and evaluate model. KDD: Evaluation.\n     </ol>\n    </blockquote>\n    <li><img style=\"float:left\" src=\"https://i.imgur.com/wpcEXQC.png\" width=\"50\">Execute - share</li>\n    <blockquote>\n    <ol>Interpret model and share the story. KDD: Communicate to stakeholders.\n     </ol>\n    </blockquote>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"top\"></a>\n<h2>Table of contents</h2>\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n<ol>\n    <li><a href=\"#Obj1\">Objectives</a></li>\n    <li><a href=\"#Plan\">Plan - import the relevant libraries and data</a></li>\n    <ul>\n        <li><a href=\"#Def\">Data Info</a></li>\n        <li><a href=\"#Clea\">Data Cleaning</a></li>  \n    </ul>\n    <li><a href=\"#EDA\">Explarotary Data Analysis (EDA)</a></li>\n    <ul>\n        <li><a href=\"#EDA_1\">Explarotary Data Analysis (EDA)</a></li>\n    </ul>\n    <li><a href=\"#Construct\">Construct - model</a></li>\n    <ul>\n        <li><a href=\"#Log_Reg\">Logistic Regression</a></li>\n    </ul>\n    <li><a href=\"#Exe\">Execute - share</a></li>\n    <ul>\n        <li><a href=\"#Sum\">Summary </a></li>\n    </ul>\n</ol>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<img style=\"float:left\" src=\"https://i.imgur.com/gIne5bH.png\" width=\"50\">\n\n<h1><a id=\"Plan\">Plan -import the relevant libraries and data</a></h1> ","metadata":{}},{"cell_type":"code","source":"# For linear algebra and data processing (available in kaggle)\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Data visualization\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport seaborn as sns\n\n# Display full dataframe columns\npd.set_option('display.max_columns', None)\n\n# Regular expressions and statistics\nimport re\nfrom scipy import stats\n\n# Machine learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    AdaBoostClassifier,\n    ExtraTreesClassifier,\n    VotingClassifier,\n    GradientBoostingClassifier\n)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier, plot_importance\nfrom lightgbm import LGBMClassifier\n\n# Preprocessing, model selection, metrics\nfrom sklearn.model_selection import (\n    train_test_split, GridSearchCV, cross_val_score,\n    StratifiedKFold, cross_validate, cross_val_predict\n)\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, ConfusionMatrixDisplay, classification_report,\n    roc_auc_score, roc_curve\n)\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n# Imbalanced learning\n#from imblearn.pipeline import Pipeline as ImbPipeline\n#from imbalanced-learn.pipeline import Pipeline\n#from imblearn.over_sampling import SMOTE\n\n# SHAP for model explainability\nimport shap\n\n# Saving/loading models\nimport joblib\nfrom joblib import dump, load\n\n# Miscellaneous\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:38:56.172763Z","iopub.execute_input":"2025-05-12T23:38:56.172990Z","iopub.status.idle":"2025-05-12T23:39:11.141883Z","shell.execute_reply.started":"2025-05-12T23:38:56.172970Z","shell.execute_reply":"2025-05-12T23:39:11.140876Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"<h2><a id=\"Def\">Data info</a></h2>\n<h3 style=\"text-align:justify; font-family: Calibri\"><br> Train.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the ‚Äúground truth‚Äù. <br> \n    <br>  The test.csv dataset contains similar information but does not disclose the ‚Äúground truth‚Äù for each passenger. It‚Äôs your job to predict these outcomes.  <br> \n   <br>   Using the patterns you find in the train.csv data, predict whether the other 418 passengers on board (found in test.csv) survived.  <br> \n  <br>    Check out the ‚ÄúData‚Äù tab to explore the datasets even further. Once you feel you‚Äôve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.</h3>","metadata":{}},{"cell_type":"markdown","source":"### Load the data","metadata":{}},{"cell_type":"code","source":"data_df = pd.read_csv('/kaggle/input/task001-p01-ml-titanic-20250407/train_df_1.csv')\nall_data_df = pd.read_csv('/kaggle/input/task001-p01-ml-titanic-20250407/all_data_df.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.143476Z","iopub.execute_input":"2025-05-12T23:39:11.144207Z","iopub.status.idle":"2025-05-12T23:39:11.183346Z","shell.execute_reply.started":"2025-05-12T23:39:11.144184Z","shell.execute_reply":"2025-05-12T23:39:11.182243Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df=all_data_df.copy()\ndf.sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.184127Z","iopub.execute_input":"2025-05-12T23:39:11.184367Z","iopub.status.idle":"2025-05-12T23:39:11.219538Z","shell.execute_reply.started":"2025-05-12T23:39:11.184345Z","shell.execute_reply":"2025-05-12T23:39:11.218776Z"}},"outputs":[{"name":"stderr","text":"invalid value encountered in greater\ninvalid value encountered in less\ninvalid value encountered in greater\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      PassengerId  Survived  Pclass                                 Name  \\\n465           466       0.0       3      Goncalves, Mr. Manuel Estanslas   \n796           797       1.0       1          Leader, Dr. Alice (Farnham)   \n647           648       1.0       1  Simonius-Blumer, Col. Oberst Alfons   \n597           598       0.0       3                  Johnson, Mr. Alfred   \n1149         1150       NaN       2              Bentham, Miss. Lilian W   \n\n         Sex   Age  SibSp  Parch              Ticket     Fare Embarked  \\\n465     male  38.0      0      0  SOTON/O.Q. 3101306   7.0500        S   \n796   female  49.0      0      0               17465  25.9292        S   \n647     male  56.0      0      0               13213  35.5000        C   \n597     male  49.0      0      0                LINE   0.0000        S   \n1149  female  19.0      0      0               28404  13.0000        S   \n\n      train_set     AgeGroup CabinGroup  CabinNo  CabinCnt  Fare_log Title  \\\n465           1        Adult          U        0         0  2.085672    Mr   \n796           1        Adult          D       17         1  3.293211    Dr   \n647           1       Senior          A       26         1  3.597312   Col   \n597           1        Adult          U        0         0  0.000000    Mr   \n1149          0  Young Adult          U        0         0  2.639057  Miss   \n\n              Surname TicketGroup FamilyGroup FareGroup  FamilySize  \n465         Goncalves     SOTONOQ        Solo       <50           1  \n796            Leader         XXX        Solo       <50           1  \n647   Simonius-Blumer         XXX        Solo       <50           1  \n597           Johnson        LINE        Solo       <50           1  \n1149          Bentham          PC        Solo     >=100           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>train_set</th>\n      <th>AgeGroup</th>\n      <th>CabinGroup</th>\n      <th>CabinNo</th>\n      <th>CabinCnt</th>\n      <th>Fare_log</th>\n      <th>Title</th>\n      <th>Surname</th>\n      <th>TicketGroup</th>\n      <th>FamilyGroup</th>\n      <th>FareGroup</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>465</th>\n      <td>466</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Goncalves, Mr. Manuel Estanslas</td>\n      <td>male</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101306</td>\n      <td>7.0500</td>\n      <td>S</td>\n      <td>1</td>\n      <td>Adult</td>\n      <td>U</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.085672</td>\n      <td>Mr</td>\n      <td>Goncalves</td>\n      <td>SOTONOQ</td>\n      <td>Solo</td>\n      <td>&lt;50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>797</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Leader, Dr. Alice (Farnham)</td>\n      <td>female</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17465</td>\n      <td>25.9292</td>\n      <td>S</td>\n      <td>1</td>\n      <td>Adult</td>\n      <td>D</td>\n      <td>17</td>\n      <td>1</td>\n      <td>3.293211</td>\n      <td>Dr</td>\n      <td>Leader</td>\n      <td>XXX</td>\n      <td>Solo</td>\n      <td>&lt;50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>647</th>\n      <td>648</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Simonius-Blumer, Col. Oberst Alfons</td>\n      <td>male</td>\n      <td>56.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13213</td>\n      <td>35.5000</td>\n      <td>C</td>\n      <td>1</td>\n      <td>Senior</td>\n      <td>A</td>\n      <td>26</td>\n      <td>1</td>\n      <td>3.597312</td>\n      <td>Col</td>\n      <td>Simonius-Blumer</td>\n      <td>XXX</td>\n      <td>Solo</td>\n      <td>&lt;50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>598</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Johnson, Mr. Alfred</td>\n      <td>male</td>\n      <td>49.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>LINE</td>\n      <td>0.0000</td>\n      <td>S</td>\n      <td>1</td>\n      <td>Adult</td>\n      <td>U</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>Mr</td>\n      <td>Johnson</td>\n      <td>LINE</td>\n      <td>Solo</td>\n      <td>&lt;50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1149</th>\n      <td>1150</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>Bentham, Miss. Lilian W</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>28404</td>\n      <td>13.0000</td>\n      <td>S</td>\n      <td>0</td>\n      <td>Young Adult</td>\n      <td>U</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.639057</td>\n      <td>Miss</td>\n      <td>Bentham</td>\n      <td>PC</td>\n      <td>Solo</td>\n      <td>&gt;=100</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.221429Z","iopub.execute_input":"2025-05-12T23:39:11.221678Z","iopub.status.idle":"2025-05-12T23:39:11.229949Z","shell.execute_reply.started":"2025-05-12T23:39:11.221661Z","shell.execute_reply":"2025-05-12T23:39:11.228919Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"PassengerId      0\nSurvived       418\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             1\nEmbarked         0\ntrain_set        0\nAgeGroup         1\nCabinGroup       0\nCabinNo          0\nCabinCnt         0\nFare_log         1\nTitle            0\nSurname          0\nTicketGroup      0\nFamilyGroup      0\nFareGroup        0\nFamilySize       0\ndtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"#### Quick fix `Age` and `Fare`","metadata":{}},{"cell_type":"code","source":"df[df['AgeGroup'].isnull()].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.230757Z","iopub.execute_input":"2025-05-12T23:39:11.231002Z","iopub.status.idle":"2025-05-12T23:39:11.260959Z","shell.execute_reply.started":"2025-05-12T23:39:11.230981Z","shell.execute_reply":"2025-05-12T23:39:11.260279Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass                                  Name  \\\n630          631       1.0       1  Barkworth, Mr. Algernon Henry Wilson   \n\n      Sex   Age  SibSp  Parch Ticket  Fare Embarked  train_set AgeGroup  \\\n630  male  80.0      0      0  27042  30.0        S          1      NaN   \n\n    CabinGroup  CabinNo  CabinCnt  Fare_log Title    Surname TicketGroup  \\\n630          A       23         1  3.433987    Mr  Barkworth         XXX   \n\n    FamilyGroup FareGroup  FamilySize  \n630        Solo       <50           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>train_set</th>\n      <th>AgeGroup</th>\n      <th>CabinGroup</th>\n      <th>CabinNo</th>\n      <th>CabinCnt</th>\n      <th>Fare_log</th>\n      <th>Title</th>\n      <th>Surname</th>\n      <th>TicketGroup</th>\n      <th>FamilyGroup</th>\n      <th>FareGroup</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>630</th>\n      <td>631</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Barkworth, Mr. Algernon Henry Wilson</td>\n      <td>male</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27042</td>\n      <td>30.0</td>\n      <td>S</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>23</td>\n      <td>1</td>\n      <td>3.433987</td>\n      <td>Mr</td>\n      <td>Barkworth</td>\n      <td>XXX</td>\n      <td>Solo</td>\n      <td>&lt;50</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df['AgeGroup'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.261731Z","iopub.execute_input":"2025-05-12T23:39:11.261952Z","iopub.status.idle":"2025-05-12T23:39:11.280039Z","shell.execute_reply.started":"2025-05-12T23:39:11.261934Z","shell.execute_reply":"2025-05-12T23:39:11.279264Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array(['Young Adult', 'Adult', 'Senior', 'Child', 'Teen', nan],\n      dtype=object)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Fill missing values in 'AgeGroup' with 'Senior' for df\ndf['AgeGroup'] = df['AgeGroup'].fillna('Senior')\n\n# Do the same for all_data_df\nall_data_df['AgeGroup'] = all_data_df['AgeGroup'].fillna('Senior')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.280855Z","iopub.execute_input":"2025-05-12T23:39:11.281088Z","iopub.status.idle":"2025-05-12T23:39:11.296629Z","shell.execute_reply.started":"2025-05-12T23:39:11.281067Z","shell.execute_reply":"2025-05-12T23:39:11.295381Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Fill missing 'Fare' values with its median\nfare_median = df['Fare'].median()\ndf['Fare'] = df['Fare'].fillna(fare_median)\n\n# Fill missing 'Fare_log' values with its median\nfare_log_median = df['Fare_log'].median()\ndf['Fare_log'] = df['Fare_log'].fillna(fare_log_median)\n\n# For all_data_df\nfare_median_all = all_data_df['Fare'].median()\nall_data_df['Fare'] = all_data_df['Fare'].fillna(fare_median_all)\n\nfare_log_median_all = all_data_df['Fare_log'].median()\nall_data_df['Fare_log'] = all_data_df['Fare_log'].fillna(fare_log_median_all)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.297641Z","iopub.execute_input":"2025-05-12T23:39:11.297878Z","iopub.status.idle":"2025-05-12T23:39:11.314967Z","shell.execute_reply.started":"2025-05-12T23:39:11.297862Z","shell.execute_reply":"2025-05-12T23:39:11.313823Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df.select_dtypes(include=[np.number]).columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.315838Z","iopub.execute_input":"2025-05-12T23:39:11.316041Z","iopub.status.idle":"2025-05-12T23:39:11.330981Z","shell.execute_reply.started":"2025-05-12T23:39:11.316026Z","shell.execute_reply":"2025-05-12T23:39:11.329932Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['PassengerId',\n 'Survived',\n 'Pclass',\n 'Age',\n 'SibSp',\n 'Parch',\n 'Fare',\n 'train_set',\n 'CabinNo',\n 'CabinCnt',\n 'Fare_log',\n 'FamilySize']"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}},{"cell_type":"markdown","source":"<img style=\"float:left\" src=\"https://i.imgur.com/rb8V6X5.png\" width=\"50\">\n\n<h1><a id=\"EDA\">Analyze - Explarotary Data Analysis (EDA)</a></h1> ","metadata":{}},{"cell_type":"markdown","source":"In <a href=\"https://www.kaggle.com/code/wahyuardhitama/task001-p01-ml-titanic-20250407\">Part 2 (P02)</a>Part 1 (P01), we conducted the P and A phase. <a href=\"https://www.kaggle.com/code/wahyuardhitama/task001-p02-ml-titanic-20250416\">Part 2 (P02)</a>, we explored 12 machine learning models, including initial tuning for Random Forest. Subsequently, part 3<a href=\"https://www.kaggle.com/code/wahyuardhitama/task001-p03-ml-titanic-20250506\"> (P03)</a> focused on further exploration and tuning of Random Forest and Support Vector Classifier (SVC) models and also we add some back to part 2.Finally, part 4 (P04) investigated boosting techniques and a Voting Classifier incorporating Boosting and Random Forest.</a>","metadata":{}},{"cell_type":"markdown","source":"### Create function","metadata":{}},{"cell_type":"code","source":"def quick_view_model(X_train, y_train, cv=5, sort_by='Accuracy'):\n    \"\"\"\n    Evaluates multiple classification models using cross-validation.\n    \n    Parameters:\n    - X_train: Training features\n    - y_train: Training labels\n    - cv: Number of cross-validation folds (default=5)\n    - sort_by: Metric to sort the result table by (default='Accuracy')\n    \n    Returns:\n    - results_df: DataFrame with mean and std CV scores for each model\n    \"\"\"\n\n    # Define models\n    models = {\n        'LogisticRegression': LogisticRegression(max_iter=1000),\n        'GaussianNB': GaussianNB(),\n        'SVC': SVC(probability=True),\n        'DecisionTree': DecisionTreeClassifier(random_state=42),\n        'RandomForest': RandomForestClassifier(random_state=42),\n        'AdaBoost': AdaBoostClassifier(random_state=42),\n        'ExtraTrees': ExtraTreesClassifier(random_state=42),\n        'GradientBoosting': GradientBoostingClassifier(random_state=42),\n        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n        'KNN': KNeighborsClassifier()\n    }\n\n    # Initialize results dictionary\n    results = {}\n\n    # Evaluate each model\n    for name, model in models.items():\n        pipe = Pipeline([\n            ('scaler', StandardScaler()),  # Can skip for tree-based\n            ('classifier', model)\n        ])\n\n        # Cross-validation\n        scores = cross_validate(\n            pipe, X_train, y_train, cv=cv,\n            scoring={\n                'accuracy': 'accuracy',\n                'auc': 'roc_auc',\n                'f1': 'f1',\n                'precision': 'precision',\n                'recall': 'recall'\n            },\n            return_train_score=False\n        )\n\n        # Store mean and std for each metric\n        results[name] = {\n            'Accuracy Mean': np.mean(scores['test_accuracy']),\n            'Accuracy Std': np.std(scores['test_accuracy']),\n            'AUC Mean': np.mean(scores['test_auc']),\n            'AUC Std': np.std(scores['test_auc']),\n            'F1-Score Mean': np.mean(scores['test_f1']),\n            'F1-Score Std': np.std(scores['test_f1']),\n            'Precision Mean': np.mean(scores['test_precision']),\n            'Precision Std': np.std(scores['test_precision']),\n            'Recall Mean': np.mean(scores['test_recall']),\n            'Recall Std': np.std(scores['test_recall'])\n        }\n\n    # Convert to DataFrame\n    results_df = pd.DataFrame(results).T\n\n    # Sort by selected mean metric\n    if f'{sort_by} Mean' in results_df.columns:\n        results_df = results_df.sort_values(by=f'{sort_by} Mean', ascending=False)\n\n    # Round for display\n    print(f\"\\nModel Comparison (sorted by {sort_by} Mean):\\n\")\n    print(results_df.round(4))\n    \n    return results_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.333633Z","iopub.execute_input":"2025-05-12T23:39:11.333825Z","iopub.status.idle":"2025-05-12T23:39:11.351314Z","shell.execute_reply.started":"2025-05-12T23:39:11.333812Z","shell.execute_reply":"2025-05-12T23:39:11.350616Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def quick_view_models_plot(results_df, metric='Accuracy'):\n    \"\"\"\n    Plots the mean and standard deviation of model performance scores.\n    \n    Parameters:\n    - results_df: DataFrame output from quick_view_model()\n    - metric: Metric to plot (e.g., 'Accuracy', 'F1-Score')\n    \"\"\"\n    # Construct column names for mean and std\n    mean_col = f\"{metric} Mean\"\n    std_col = f\"{metric} Std\"\n\n    # Check if metric exists\n    if mean_col not in results_df.columns or std_col not in results_df.columns:\n        raise ValueError(f\"Metric '{metric}' not found in results_df. Check column names.\")\n\n    # Drop GaussianNB if present\n    filtered_df = results_df.drop(index='GaussianNB', errors='ignore')\n\n    # Plotting data\n    models = filtered_df.index\n    mean_scores = filtered_df[mean_col]\n    std_devs = filtered_df[std_col]\n    x_pos = np.arange(len(models))\n\n    # Plot\n    plt.figure(figsize=(12, 8))\n    plt.errorbar(x_pos, mean_scores, yerr=std_devs, fmt='o-', linewidth=2, capsize=6,\n                 markersize=8, label=f'Mean {metric} ¬± Std Dev')\n    plt.fill_between(x_pos, mean_scores - std_devs, mean_scores + std_devs,\n                     alpha=0.2, color='skyblue')\n\n    plt.xticks(x_pos, models, rotation=45, ha='right')\n    plt.grid(True, linestyle='--', alpha=0.7)\n    plt.xlabel('Models', fontsize=12, fontweight='bold')\n    plt.ylabel(f'{metric} Score', fontsize=12, fontweight='bold')\n    plt.title(f'Model Comparison (Excl. GaussianNB) - {metric}', fontsize=14, fontweight='bold')\n\n    # Annotate each point\n    for i, (m, s) in enumerate(zip(mean_scores, std_devs)):\n        plt.text(i, m + 0.002, f\"{m:.3f}¬±{s:.3f}\", ha='center', fontsize=9)\n\n    plt.ylim(min(mean_scores - std_devs) - 0.02, max(mean_scores + std_devs) + 0.02)\n    plt.legend(loc='lower right')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.352342Z","iopub.execute_input":"2025-05-12T23:39:11.352641Z","iopub.status.idle":"2025-05-12T23:39:11.372371Z","shell.execute_reply.started":"2025-05-12T23:39:11.352618Z","shell.execute_reply":"2025-05-12T23:39:11.371445Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def quick_view_models_chart(results_df, metrics=None):\n    \"\"\"\n    Plots a grouped bar chart to compare multiple evaluation metrics (Mean) across models.\n    \"\"\"\n    if metrics is None:\n        metrics = ['Accuracy Mean', 'AUC Mean', 'F1-Score Mean', 'Precision Mean', 'Recall Mean']\n\n    # Drop GaussianNB if present\n    #results_df = results_df.drop(index='GaussianNB', errors='ignore')\n    models = results_df.index\n    x = np.arange(len(models))\n    width = 0.13\n\n    colors = ['skyblue', 'orange', 'lightgreen', 'salmon', 'violet']\n    if len(metrics) > len(colors):\n        raise ValueError(\"Too many metrics. Add more colors.\")\n\n    plt.figure(figsize=(16, 8))\n\n    for i, metric in enumerate(metrics):\n        if metric not in results_df.columns:\n            raise ValueError(f\"Metric '{metric}' not found in results_df.\")\n        values = results_df[metric]\n        plt.bar(x + i * width, values, width, label=metric, color=colors[i])\n\n        for j, val in enumerate(values):\n            plt.text(j + i * width, val + 0.015, f\"{val:.2f}\", ha='center', fontsize=8)\n\n    plt.ylabel('Score', fontsize=12, fontweight='bold')\n    plt.title('Model Comparison by Evaluation Metrics (Mean)', fontsize=14, fontweight='bold')\n    plt.xticks(x + width * (len(metrics)-1) / 2, models, rotation=45, ha='right')\n    plt.ylim(0, 1.1)\n    plt.grid(axis='y', linestyle='--', alpha=0.5)\n    plt.legend(title=\"Metrics\", loc='upper right')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.372975Z","iopub.execute_input":"2025-05-12T23:39:11.373221Z","iopub.status.idle":"2025-05-12T23:39:11.389737Z","shell.execute_reply.started":"2025-05-12T23:39:11.373201Z","shell.execute_reply":"2025-05-12T23:39:11.389111Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}},{"cell_type":"markdown","source":"<img style=\"float:left\" src=\"https://i.imgur.com/J4M3HKM.png\" width=\"50\">\n\n<h1><a id=\"Construct\">Construct - model</a></h1>  ","metadata":{}},{"cell_type":"markdown","source":"### Baseline feature selection (original 83 Features, lightly imbalanced data)","metadata":{}},{"cell_type":"code","source":"#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.390416Z","iopub.execute_input":"2025-05-12T23:39:11.390718Z","iopub.status.idle":"2025-05-12T23:39:11.415075Z","shell.execute_reply.started":"2025-05-12T23:39:11.390699Z","shell.execute_reply":"2025-05-12T23:39:11.414214Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Convert the 'Pclass' and 'FamilySize' columns to string (object) type for pd.get_dummies() Using this will acquire 83 features\n# Let us apply without converting to string\ndf[['Pclass', 'FamilySize']] = df[['Pclass', 'FamilySize']].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.416127Z","iopub.execute_input":"2025-05-12T23:39:11.416476Z","iopub.status.idle":"2025-05-12T23:39:11.442598Z","shell.execute_reply.started":"2025-05-12T23:39:11.416448Z","shell.execute_reply":"2025-05-12T23:39:11.441112Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.443734Z","iopub.execute_input":"2025-05-12T23:39:11.444293Z","iopub.status.idle":"2025-05-12T23:39:11.465978Z","shell.execute_reply.started":"2025-05-12T23:39:11.444268Z","shell.execute_reply":"2025-05-12T23:39:11.464974Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Embarked', 'train_set', 'AgeGroup',\n       'CabinGroup', 'CabinNo', 'CabinCnt', 'Fare_log', 'Title', 'Surname',\n       'TicketGroup', 'FamilyGroup', 'FareGroup', 'FamilySize'],\n      dtype='object')"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Created dummy variablesfrom categories (also can use OneHotEncoder)\ndf_dummies = pd.get_dummies(df[['Pclass', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Embarked', 'train_set',\n       'CabinGroup', 'CabinCnt', 'Fare_log', 'Title',\n       'TicketGroup', 'FamilyGroup','FamilySize']])\n\nX_train = df_dummies[df_dummies.train_set == 1].drop(['train_set'],axis=1)\nX_test = df_dummies[df_dummies.train_set == 0].drop(['train_set'], axis=1)\n\ny_train = df[df.train_set==1].Survived\ny_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.466747Z","iopub.execute_input":"2025-05-12T23:39:11.467054Z","iopub.status.idle":"2025-05-12T23:39:11.506136Z","shell.execute_reply.started":"2025-05-12T23:39:11.467036Z","shell.execute_reply":"2025-05-12T23:39:11.504841Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(891,)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.507105Z","iopub.execute_input":"2025-05-12T23:39:11.507489Z","iopub.status.idle":"2025-05-12T23:39:11.544146Z","shell.execute_reply.started":"2025-05-12T23:39:11.507460Z","shell.execute_reply":"2025-05-12T23:39:11.543387Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"    Age  SibSp  Parch  CabinCnt  Fare_log  Pclass_1  Pclass_2  Pclass_3  \\\n0  22.0      1      0         0  2.110213     False     False      True   \n1  38.0      1      0         1  4.280593      True     False     False   \n2  26.0      0      0         0  2.188856     False     False      True   \n3  35.0      1      0         1  3.990834      True     False     False   \n4  35.0      0      0         0  2.202765     False     False      True   \n\n   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  CabinGroup_A  \\\n0       False      True       False       False        True         False   \n1        True     False        True       False       False         False   \n2        True     False       False       False        True         False   \n3        True     False       False       False        True         False   \n4       False      True       False       False        True         False   \n\n   CabinGroup_B  CabinGroup_C  CabinGroup_D  CabinGroup_E  CabinGroup_F  \\\n0         False         False         False         False         False   \n1         False          True         False         False         False   \n2         False         False         False         False         False   \n3         False          True         False         False         False   \n4         False         False         False         False         False   \n\n   CabinGroup_G  CabinGroup_T  CabinGroup_U  Title_Capt  Title_Col  Title_Don  \\\n0         False         False          True       False      False      False   \n1         False         False         False       False      False      False   \n2         False         False          True       False      False      False   \n3         False         False         False       False      False      False   \n4         False         False          True       False      False      False   \n\n   Title_Dona  Title_Dr  Title_Jonkheer  Title_Lady  Title_Major  \\\n0       False     False           False       False        False   \n1       False     False           False       False        False   \n2       False     False           False       False        False   \n3       False     False           False       False        False   \n4       False     False           False       False        False   \n\n   Title_Master  Title_Miss  Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n0         False       False       False      False      True      False   \n1         False       False       False      False     False       True   \n2         False        True       False      False     False      False   \n3         False       False       False      False     False       True   \n4         False       False       False      False      True      False   \n\n   Title_Ms  Title_Rev  Title_Sir  Title_the Countess  TicketGroup_A4  \\\n0     False      False      False               False           False   \n1     False      False      False               False           False   \n2     False      False      False               False           False   \n3     False      False      False               False           False   \n4     False      False      False               False           False   \n\n   TicketGroup_A5  TicketGroup_AS  TicketGroup_C  TicketGroup_CA  \\\n0            True           False          False           False   \n1           False           False          False           False   \n2           False           False          False           False   \n3           False           False          False           False   \n4           False           False          False           False   \n\n   TicketGroup_CASOTON  TicketGroup_FC  TicketGroup_FCC  TicketGroup_Fa  \\\n0                False           False            False           False   \n1                False           False            False           False   \n2                False           False            False           False   \n3                False           False            False           False   \n4                False           False            False           False   \n\n   TicketGroup_LINE  TicketGroup_PC  TicketGroup_PP  TicketGroup_PPP  \\\n0             False           False           False            False   \n1             False            True           False            False   \n2             False           False           False            False   \n3             False           False           False            False   \n4             False           False           False            False   \n\n   TicketGroup_SC  TicketGroup_SCA4  TicketGroup_SCAH  TicketGroup_SCOW  \\\n0           False             False             False             False   \n1           False             False             False             False   \n2           False             False             False             False   \n3           False             False             False             False   \n4           False             False             False             False   \n\n   TicketGroup_SCPARIS  TicketGroup_SCParis  TicketGroup_SOC  TicketGroup_SOP  \\\n0                False                False            False            False   \n1                False                False            False            False   \n2                False                False            False            False   \n3                False                False            False            False   \n4                False                False            False            False   \n\n   TicketGroup_SOPP  TicketGroup_SOTONO2  TicketGroup_SOTONOQ  TicketGroup_SP  \\\n0             False                False                False           False   \n1             False                False                False           False   \n2             False                False                False           False   \n3             False                False                False           False   \n4             False                False                False           False   \n\n   TicketGroup_STONO  TicketGroup_STONO2  TicketGroup_SWPP  TicketGroup_WC  \\\n0              False               False             False           False   \n1              False               False             False           False   \n2              False                True             False           False   \n3              False               False             False           False   \n4              False               False             False           False   \n\n   TicketGroup_WEP  TicketGroup_XXX  FamilyGroup_Large Family  \\\n0            False            False                     False   \n1            False            False                     False   \n2            False            False                     False   \n3            False             True                     False   \n4            False             True                     False   \n\n   FamilyGroup_Small Family  FamilyGroup_Solo  FamilySize_1  FamilySize_11  \\\n0                      True             False         False          False   \n1                      True             False         False          False   \n2                     False              True          True          False   \n3                      True             False         False          False   \n4                     False              True          True          False   \n\n   FamilySize_2  FamilySize_3  FamilySize_4  FamilySize_5  FamilySize_6  \\\n0          True         False         False         False         False   \n1          True         False         False         False         False   \n2         False         False         False         False         False   \n3          True         False         False         False         False   \n4         False         False         False         False         False   \n\n   FamilySize_7  FamilySize_8  \n0         False         False  \n1         False         False  \n2         False         False  \n3         False         False  \n4         False         False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>CabinCnt</th>\n      <th>Fare_log</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n      <th>CabinGroup_A</th>\n      <th>CabinGroup_B</th>\n      <th>CabinGroup_C</th>\n      <th>CabinGroup_D</th>\n      <th>CabinGroup_E</th>\n      <th>CabinGroup_F</th>\n      <th>CabinGroup_G</th>\n      <th>CabinGroup_T</th>\n      <th>CabinGroup_U</th>\n      <th>Title_Capt</th>\n      <th>Title_Col</th>\n      <th>Title_Don</th>\n      <th>Title_Dona</th>\n      <th>Title_Dr</th>\n      <th>Title_Jonkheer</th>\n      <th>Title_Lady</th>\n      <th>Title_Major</th>\n      <th>Title_Master</th>\n      <th>Title_Miss</th>\n      <th>Title_Mlle</th>\n      <th>Title_Mme</th>\n      <th>Title_Mr</th>\n      <th>Title_Mrs</th>\n      <th>Title_Ms</th>\n      <th>Title_Rev</th>\n      <th>Title_Sir</th>\n      <th>Title_the Countess</th>\n      <th>TicketGroup_A4</th>\n      <th>TicketGroup_A5</th>\n      <th>TicketGroup_AS</th>\n      <th>TicketGroup_C</th>\n      <th>TicketGroup_CA</th>\n      <th>TicketGroup_CASOTON</th>\n      <th>TicketGroup_FC</th>\n      <th>TicketGroup_FCC</th>\n      <th>TicketGroup_Fa</th>\n      <th>TicketGroup_LINE</th>\n      <th>TicketGroup_PC</th>\n      <th>TicketGroup_PP</th>\n      <th>TicketGroup_PPP</th>\n      <th>TicketGroup_SC</th>\n      <th>TicketGroup_SCA4</th>\n      <th>TicketGroup_SCAH</th>\n      <th>TicketGroup_SCOW</th>\n      <th>TicketGroup_SCPARIS</th>\n      <th>TicketGroup_SCParis</th>\n      <th>TicketGroup_SOC</th>\n      <th>TicketGroup_SOP</th>\n      <th>TicketGroup_SOPP</th>\n      <th>TicketGroup_SOTONO2</th>\n      <th>TicketGroup_SOTONOQ</th>\n      <th>TicketGroup_SP</th>\n      <th>TicketGroup_STONO</th>\n      <th>TicketGroup_STONO2</th>\n      <th>TicketGroup_SWPP</th>\n      <th>TicketGroup_WC</th>\n      <th>TicketGroup_WEP</th>\n      <th>TicketGroup_XXX</th>\n      <th>FamilyGroup_Large Family</th>\n      <th>FamilyGroup_Small Family</th>\n      <th>FamilyGroup_Solo</th>\n      <th>FamilySize_1</th>\n      <th>FamilySize_11</th>\n      <th>FamilySize_2</th>\n      <th>FamilySize_3</th>\n      <th>FamilySize_4</th>\n      <th>FamilySize_5</th>\n      <th>FamilySize_6</th>\n      <th>FamilySize_7</th>\n      <th>FamilySize_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.110213</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4.280593</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.188856</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.990834</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.202765</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.544854Z","iopub.execute_input":"2025-05-12T23:39:11.545086Z","iopub.status.idle":"2025-05-12T23:39:11.550538Z","shell.execute_reply.started":"2025-05-12T23:39:11.545067Z","shell.execute_reply":"2025-05-12T23:39:11.549809Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(891, 83)"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameter tuning (1st)\n### Logistic regression","metadata":{}},{"cell_type":"code","source":"def model_log_selection(X_train, y_train, cv=5, scoring='accuracy', class_weight=False):\n    \"\"\"\n    Performs hyperparameter tuning for LogisticRegression (L2 penalty only) using GridSearchCV.\n\n    Parameters:\n        X_train (pd.DataFrame): Training features.\n        y_train (pd.Series or np.array): Training target.\n        cv (int): Number of cross-validation folds (default is 5).\n        scoring (str): Scoring metric (default is 'accuracy').\n        class_weight (bool): Whether to apply class_weight='balanced' (default is False).\n\n    Returns:\n        GridSearchCV object (fitted)\n    \"\"\"\n\n    class_weight = 'balanced' if class_weight else None\n\n    pipe_lr = Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', LogisticRegression(\n            penalty='l2',\n            max_iter=1000,\n            class_weight=class_weight,\n            random_state=42\n        ))\n    ])\n\n    param_grid = {\n        'classifier__C': [0.01, 0.1, 1, 10, 100],\n        'classifier__solver': ['lbfgs', 'saga']  # both support l2\n    }\n\n    grid_search = GridSearchCV(\n        pipe_lr,\n        param_grid,\n        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n        scoring=scoring,\n        n_jobs=-1,\n        verbose=1\n    )\n    \n    grid_search.fit(X_train, y_train)\n\n    print(\"Best Parameters:\", grid_search.best_params_)\n    print(f\"Best {scoring.capitalize()} Score: {grid_search.best_score_:.4f}\")\n\n    return grid_search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.551432Z","iopub.execute_input":"2025-05-12T23:39:11.552098Z","iopub.status.idle":"2025-05-12T23:39:11.573415Z","shell.execute_reply.started":"2025-05-12T23:39:11.552075Z","shell.execute_reply":"2025-05-12T23:39:11.571934Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"#### Model 1: Logistic, lighly imbalanced data and 83 features","metadata":{}},{"cell_type":"code","source":"%%time\n#6min 24s\nmodel_log_1 = model_log_selection(X_train, y_train, cv=5, scoring='accuracy', class_weight=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:11.574554Z","iopub.execute_input":"2025-05-12T23:39:11.574906Z","iopub.status.idle":"2025-05-12T23:39:16.185031Z","shell.execute_reply.started":"2025-05-12T23:39:11.574881Z","shell.execute_reply":"2025-05-12T23:39:16.183305Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'classifier__C': 0.01, 'classifier__solver': 'lbfgs'}\nBest Accuracy Score: 0.8193\nCPU times: user 172 ms, sys: 23.3 ms, total: 195 ms\nWall time: 4.59 s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Save to file after fitting\n#dump(model_log_1, 'model_log_1.joblib')\n#model_log_1.best_estimator_\n\n# Load it later when needed\ngrid_loaded = load('/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_log_1.joblib')\n\n# Access best estimator\nmodel_log_1 = grid_loaded.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:16.185593Z","iopub.execute_input":"2025-05-12T23:39:16.186466Z","iopub.status.idle":"2025-05-12T23:39:16.227904Z","shell.execute_reply.started":"2025-05-12T23:39:16.186446Z","shell.execute_reply":"2025-05-12T23:39:16.226308Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4039143893.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load it later when needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrid_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_log_1.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Access best estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             with _validate_fileobject_and_memmap(f, filename, mmap_mode) as (\n\u001b[1;32m    737\u001b[0m                 \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_log_1.joblib'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_log_1.joblib'","output_type":"error"}],"execution_count":24},{"cell_type":"markdown","source":"<h4> When feature engineering is done, we usually tend to decrease the dimensionality by selecting the \"right\" number of features that capture the essential.\nIn fact, feature selection comes with many benefits:\n<ul>\n    <li>It decreases redundancy among the data\n    <li>It speeds up the training process\n    <li>It reduces overfitting</ul>\nTree-based estimators can be used to compute feature importances, which in turn can be used to discard irrelevant features.\n</h4>","metadata":{}},{"cell_type":"code","source":"def train_and_predict(model, X_train, y_train, X_test, test_ids, cv=5, submission_name='submission.csv'):\n    \"\"\"\n    Trains the model, performs cross-validation, and makes predictions on the test set.\n\n    Parameters:\n    - model: Machine learning model with fit/predict methods\n    - X_train: Training features\n    - y_train: Training labels\n    - X_test: Test features\n    - test_ids: IDs for submission (e.g., PassengerId)\n    - cv: Number of cross-validation folds (default=5)\n    - submission_name: Filename for the CSV submission\n    \"\"\"\n    \n    # Step 1: Train the model\n    model.fit(X_train, y_train)\n    \n    # Step 2: Cross-validation\n    scores = cross_val_score(model, X_train, y_train, cv=cv)\n    print(\"Cross-validation scores:\", scores)\n    print(\"Mean cross-validation score:\", scores.mean())\n    \n    # Step 3: Retrain (optional here, just to match original process)\n    model.fit(X_train, y_train)\n    \n    # Step 4: Predict\n    y_pred = model.predict(X_test).astype(int)\n    \n    # Step 5: Create submission\n    submission = pd.DataFrame({\n        'PassengerId': test_ids,\n        'Survived': y_pred\n    })\n    \n    submission.to_csv(submission_name, index=False)\n    print(f\"Submission saved to {submission_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:41:13.554835Z","iopub.execute_input":"2025-05-12T23:41:13.555364Z","iopub.status.idle":"2025-05-12T23:41:13.561429Z","shell.execute_reply.started":"2025-05-12T23:41:13.555340Z","shell.execute_reply":"2025-05-12T23:41:13.560394Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def compute_metrics_df(models, X, y, cv):\n    \"\"\"\n    Computes cross-validated metrics for a list of models and returns a sorted DataFrame.\n    \n    Parameters:\n        models (list): List of tuples like [('Model Name', model_instance), ...]\n        X (pd.DataFrame): Feature data.\n        y (pd.Series or np.array): Target values.\n    \n    Returns:\n        pd.DataFrame: DataFrame of metrics sorted by Accuracy Mean.\n    \"\"\"\n    results = []\n\n    for name, model in models:\n        # Cross-validated accuracy scores\n        accuracy_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n\n        # Cross-validated predictions and predicted probabilities\n        y_pred = cross_val_predict(model, X, y, cv=cv)\n        y_proba = cross_val_predict(model, X, y, cv=cv, method='predict_proba')[:, 1]\n\n        # Collect metrics\n        metrics = {\n            'Model': name,\n            'Accuracy Mean': np.mean(accuracy_scores),\n            'Accuracy Std': np.std(accuracy_scores),\n            'AUC': roc_auc_score(y, y_proba),\n            'F1 Score': f1_score(y, y_pred),\n            'Precision': precision_score(y, y_pred),\n            'Recall': recall_score(y, y_pred)\n        }\n        results.append(metrics)\n\n    # Convert to DataFrame and sort\n    metrics_df = pd.DataFrame(results)\n    metrics_df.sort_values(by='Accuracy Mean', ascending=False, inplace=True)\n    \n    return metrics_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:41:13.900677Z","iopub.execute_input":"2025-05-12T23:41:13.900965Z","iopub.status.idle":"2025-05-12T23:41:13.907834Z","shell.execute_reply.started":"2025-05-12T23:41:13.900946Z","shell.execute_reply":"2025-05-12T23:41:13.906885Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"%%time\n#566 ms\ntrain_and_predict(\n    model=model_log_1, # Tweak to find the best model and try other ml models\n    X_train=X_train, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_log_1.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:16.230085Z","iopub.status.idle":"2025-05-12T23:39:16.230251Z","shell.execute_reply.started":"2025-05-12T23:39:16.230161Z","shell.execute_reply":"2025-05-12T23:39:16.230170Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Score at kaggle 77.3%","metadata":{}},{"cell_type":"code","source":"%%time\n# Define your model list\nmodels = [\n    ('LogisticRegression', model_log_1),\n    # Add more models if needed\n]\n\n# Get the metrics DataFrame\nmetrics_df = compute_metrics_df(models, X_train, y_train, cv=5)\nmetrics_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Importance\n### Random Forest","metadata":{}},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}},{"cell_type":"code","source":"def top_feature_importance_plot(model, X_train, top_n='pareto', classifier_step='classifier', figsize=(10, 8), save_path=None):\n    \"\"\"\n    Plot feature importances using either Pareto principle (80% cumulative) or top N features.\n\n    Parameters:\n    - model: fitted pipeline model (e.g., Pipeline with classifier step)\n    - X_train: training dataset used to retrieve feature names\n    - top_n: 'pareto' to use 80% cumulative importance, or integer for top N features\n    - classifier_step: name of the classifier step in pipeline (default: 'classifier')\n    - figsize: size of the plot\n    - save_path: if provided, saves the plot to the given file path\n    \"\"\"\n    # Get feature names\n    feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\n    \n    # Extract feature importances\n    importances = model.named_steps[classifier_step].feature_importances_\n    sorted_idx = np.argsort(importances)[::-1]  # descending order\n\n    if top_n == 'pareto':\n        # Compute cumulative importances\n        cum_importance = np.cumsum(importances[sorted_idx])\n        # Find cutoff for 80% cumulative importance\n        pareto_cutoff = np.argmax(cum_importance >= 0.8) + 1\n        selected_idx = sorted_idx[:pareto_cutoff]\n        title_suffix = 'Top Features (Pareto 80%)'\n    elif isinstance(top_n, int):\n        selected_idx = sorted_idx[:top_n]\n        title_suffix = f'Top {top_n} Features'\n    else:\n        raise ValueError(\"top_n must be an integer or 'pareto'\")\n\n    # Plot\n    plt.figure(figsize=figsize)\n    plt.barh(\n        [feature_names[i] for i in selected_idx][::-1],\n        importances[selected_idx][::-1],\n        color='skyblue'\n    )\n    plt.xlabel('Gini Importance', fontsize=12)\n    plt.title(f'Feature Importance - {title_suffix}', fontsize=14, pad=20)\n    plt.gca().invert_yaxis()\n    plt.grid(axis='x', linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    \n    # Save or show\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def reduce_features_with_importance(model, X_train, X_test, classifier_step='classifier', threshold='pareto'):\n    \"\"\"\n    Reduces features in X_train and X_test based on feature importances using:\n    - 'pareto' (default): top features that cumulatively contribute to 80% of total importance\n    - 'mean': selects features above the mean importance\n    - float: custom importance threshold\n\n    Parameters:\n    - model: fitted pipeline model (e.g., Pipeline with a classifier)\n    - X_train: training data (DataFrame or ndarray)\n    - X_test: test data (same structure as X_train)\n    - classifier_step: name of the classifier step in the pipeline\n    - threshold: 'pareto' (default), 'mean', float, or valid SelectFromModel threshold\n\n    Returns:\n    - X_train_reduced: training data with selected features\n    - X_test_reduced: test data with selected features\n    - selected_feature_names: list of retained feature names\n    \"\"\"\n    clf = model.named_steps[classifier_step]\n    importances = clf.feature_importances_\n\n    feature_names = (\n        X_train.columns if hasattr(X_train, 'columns')\n        else [f'feature_{i}' for i in range(X_train.shape[1])]\n    )\n\n    if threshold == 'pareto':\n        sorted_idx = np.argsort(importances)[::-1]\n        sorted_importances = importances[sorted_idx]\n        cumulative = np.cumsum(sorted_importances)\n        pareto_cutoff = np.argmax(cumulative >= 0.8) + 1\n        threshold_value = sorted_importances[pareto_cutoff - 1]\n        selector = SelectFromModel(clf, threshold=threshold_value, prefit=True)\n    else:\n        selector = SelectFromModel(clf, threshold=threshold, prefit=True)\n\n    # Transform the data\n    X_train_reduced = selector.transform(X_train)\n    X_test_reduced = selector.transform(X_test)\n\n    # Get selected feature names\n    selected_mask = selector.get_support()\n    selected_feature_names = [name for name, selected in zip(feature_names, selected_mask) if selected]\n\n    print(\"Reduced X_train shape:\", X_train_reduced.shape)\n    print(\"Reduced X_test shape:\", X_test_reduced.shape)\n\n    return X_train_reduced, X_test_reduced, selected_feature_names","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}},{"cell_type":"code","source":"# Load it later when needed\ngrid_loaded = load('/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_rf_1.joblib')\n\n# Access best estimator\nmodel_rf_1 = grid_loaded.best_estimator_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_reduced_1, X_test_reduced_1, selected_features = reduce_features_with_importance(model_rf_1, X_train, X_test, \n                                                                                         classifier_step='classifier', \n                                                                                         threshold='mean')\nprint(\"Selected Features:\", selected_features)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Model 2: Logistic Regression, lightly imbalanced data and 17 features\n\nBest Parameters: {'classifier__C': 0.01, 'classifier__solver': 'lbfgs'}","metadata":{}},{"cell_type":"code","source":"# Define the pipeline with Logistic Regression and L2 regularization\nmodel_log_2 = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', LogisticRegression(\n        penalty='l2',\n        C=0.01,                # Regularization strength (default)\n        solver='lbfgs',       # Solver that supports L2\n        max_iter=1000,        # Ensures convergence\n        random_state=42,\n        class_weight=None     # Or 'balanced' if needed\n    ))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:16.236839Z","iopub.status.idle":"2025-05-12T23:39:16.237011Z","shell.execute_reply.started":"2025-05-12T23:39:16.236921Z","shell.execute_reply":"2025-05-12T23:39:16.236929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n#1.5s\ntrain_and_predict(\n    model=model_log_2, # Tweak to find the best model and try other ml models\n    X_train=X_train_reduced_1, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test_reduced_1, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_log_2.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:16.237274Z","iopub.status.idle":"2025-05-12T23:39:16.237431Z","shell.execute_reply.started":"2025-05-12T23:39:16.237346Z","shell.execute_reply":"2025-05-12T23:39:16.237354Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Kaggle Score 78.5%","metadata":{}},{"cell_type":"code","source":"# Save to file after fitting\n#dump(model_rf_3, 'model_rf_3.joblib')\n#model_rf_3.best_estimator_\n\n# Load it later when needed\ngrid_loaded = load('/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_rf_3.joblib')\n\n# Access best estimator\nmodel_rf_3 = grid_loaded.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:16.241994Z","iopub.status.idle":"2025-05-12T23:39:16.243268Z","shell.execute_reply.started":"2025-05-12T23:39:16.243109Z","shell.execute_reply":"2025-05-12T23:39:16.243122Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Light Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"#### We skipped Light Gradient Boosting as it takes longer time and there was an error to the notebook","metadata":{}},{"cell_type":"code","source":"def model_lgb_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False):\n    \"\"\"\n    Performs hyperparameter tuning for LGBMClassifier using GridSearchCV.\n\n    Parameters:\n        X_train (pd.DataFrame): Training features.\n        y_train (pd.Series or np.array): Training target.\n        cv (int): Number of cross-validation folds (default is 5).\n        scoring (str): Scoring metric (default is 'accuracy').\n        use_sample_weight (bool): Whether to apply sample_weight as 'balanced'.\n\n    Returns:\n        GridSearchCV object (fitted)\n    \"\"\"\n    # Compute sample weights if specified\n    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train) if use_sample_weight else None\n\n    # Define pipeline\n    pipe_lgb = Pipeline([\n        ('classifier', LGBMClassifier(random_state=42))\n    ])\n\n    # Define parameter grid\n    param_grid = {\n        'classifier__learning_rate': [0.01, 0.1],\n        'classifier__n_estimators': [100, 200],\n        'classifier__subsample': [0.8, 1.0],\n        'classifier__num_leaves': [31, 50],\n        'classifier__max_depth': [3, 5, -1],  # -1 means no limit in LightGBM\n        'classifier__min_child_samples': [20, 50],\n        'classifier__colsample_bytree': [0.8, 1.0]\n    }\n\n    # Define GridSearchCV\n    grid_search = GridSearchCV(\n        pipe_lgb,\n        param_grid,\n        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n        scoring=scoring,\n        n_jobs=-1,\n        verbose=1\n    )\n\n    # Fit model with or without sample_weight\n    if use_sample_weight:\n        grid_search.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n    else:\n        grid_search.fit(X_train, y_train)\n\n    print(\"Best Parameters:\", grid_search.best_params_)\n    print(f\"Best {scoring.capitalize()} Score: {grid_search.best_score_:.4f}\")\n\n    return grid_search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:16.243706Z","iopub.status.idle":"2025-05-12T23:39:16.243896Z","shell.execute_reply.started":"2025-05-12T23:39:16.243801Z","shell.execute_reply":"2025-05-12T23:39:16.243810Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Gradient Boosting","metadata":{}},{"cell_type":"code","source":"def model_gb_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False):\n    \"\"\"\n    Performs hyperparameter tuning for GradientBoostingClassifier using GridSearchCV.\n\n    Parameters:\n        X_train (pd.DataFrame): Training features.\n        y_train (pd.Series or np.array): Training target.\n        cv (int): Number of cross-validation folds (default is 5).\n        scoring (str): Scoring metric (default is 'accuracy').\n        use_sample_weight (bool): Whether to apply sample_weight as 'balanced'.\n\n    Returns:\n        GridSearchCV object (fitted)\n    \"\"\"\n    \n    # Compute sample weights if specified\n    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train) if use_sample_weight else None\n\n    # Define pipeline\n    pipe_gb = Pipeline([\n        ('classifier', GradientBoostingClassifier(random_state=42))\n    ])\n\n    # Define parameter grid (focused on practical parameters)\n    param_grid = {\n        'classifier__loss': ['log_loss'],\n        'classifier__learning_rate': [0.01, 0.1],\n        'classifier__n_estimators': [100, 200],\n        'classifier__subsample': [0.8, 1.0],\n        'classifier__min_samples_split': [2, 5],\n        'classifier__min_samples_leaf': [1, 3],\n        'classifier__max_depth': [3, 5],\n        'classifier__max_features': ['sqrt', 'log2'],\n        'classifier__ccp_alpha': [0.0]\n    }\n\n    # Define GridSearchCV\n    grid_search = GridSearchCV(\n        pipe_gb,\n        param_grid,\n        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n        scoring=scoring,\n        n_jobs=-1,\n        verbose=1\n    )\n\n    # Fit model with or without sample_weight\n    if use_sample_weight:\n        grid_search.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n    else:\n        grid_search.fit(X_train, y_train)\n\n    print(\"Best Parameters:\", grid_search.best_params_)\n    print(f\"Best {scoring.capitalize()} Score: {grid_search.best_score_:.4f}\")\n\n    return grid_search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:52.257094Z","iopub.execute_input":"2025-05-12T23:39:52.257361Z","iopub.status.idle":"2025-05-12T23:39:52.263828Z","shell.execute_reply.started":"2025-05-12T23:39:52.257342Z","shell.execute_reply":"2025-05-12T23:39:52.262941Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"%%time\n#51.4s\nmodel_gb_1 = model_gb_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:39:54.639099Z","iopub.execute_input":"2025-05-12T23:39:54.639349Z","iopub.status.idle":"2025-05-12T23:40:26.623787Z","shell.execute_reply.started":"2025-05-12T23:39:54.639327Z","shell.execute_reply":"2025-05-12T23:40:26.622734Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nBest Parameters: {'classifier__ccp_alpha': 0.0, 'classifier__learning_rate': 0.01, 'classifier__loss': 'log_loss', 'classifier__max_depth': 5, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 1.0}\nBest Accuracy Score: 0.8395\nCPU times: user 1.22 s, sys: 108 ms, total: 1.33 s\nWall time: 32 s\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Save to file after fitting\ndump(model_gb_1, 'model_gb_1.joblib')\nmodel_gb_1.best_estimator_\n\n# Load it later when needed\n#grid_loaded = load('/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_gb_1.joblib')\n\n# Access best estimator\n#model_gb_1 = grid_loaded.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:40:26.624962Z","iopub.execute_input":"2025-05-12T23:40:26.625225Z","iopub.status.idle":"2025-05-12T23:40:26.654740Z","shell.execute_reply.started":"2025-05-12T23:40:26.625203Z","shell.execute_reply":"2025-05-12T23:40:26.653900Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('classifier',\n                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n                                            max_features='sqrt',\n                                            min_samples_split=5,\n                                            n_estimators=200,\n                                            random_state=42))])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n                                            max_features=&#x27;sqrt&#x27;,\n                                            min_samples_split=5,\n                                            n_estimators=200,\n                                            random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n                                            max_features=&#x27;sqrt&#x27;,\n                                            min_samples_split=5,\n                                            n_estimators=200,\n                                            random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01, max_depth=5, max_features=&#x27;sqrt&#x27;,\n                           min_samples_split=5, n_estimators=200,\n                           random_state=42)</pre></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"%%time\n#5 min 25s\ntrain_and_predict(\n    model=model_gb_1, # Tweak to find the best model and try other ml models\n    X_train=X_train, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_gb_1.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:41:29.091839Z","iopub.execute_input":"2025-05-12T23:41:29.092079Z","iopub.status.idle":"2025-05-12T23:45:02.148020Z","shell.execute_reply.started":"2025-05-12T23:41:29.092061Z","shell.execute_reply":"2025-05-12T23:45:02.147044Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nCross-validation scores: [0.84357542 0.82022472 0.83146067 0.79213483 0.84269663]\nMean cross-validation score: 0.8260184545853996\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nSubmission saved to submit_gb_1.csv\nCPU times: user 8.16 s, sys: 693 ms, total: 8.86 s\nWall time: 3min 33s\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"%%time\n#7min 30s\n# Define your model list\nmodels = [\n    ('GradientBoosting', model_gb_1),\n    # Add more models if needed\n]\n\n# Get the metrics DataFrame\nmetrics_df = compute_metrics_df(models, X_train, y_train, cv=5)\nmetrics_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:54:24.903081Z","iopub.execute_input":"2025-05-12T23:54:24.903336Z","iopub.status.idle":"2025-05-13T00:01:55.293794Z","shell.execute_reply.started":"2025-05-12T23:54:24.903320Z","shell.execute_reply":"2025-05-13T00:01:55.292664Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 128 candidates, totalling 640 fits\nCPU times: user 17.7 s, sys: 1.24 s, total: 19 s\nWall time: 7min 30s\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"              Model  Accuracy Mean  Accuracy Std      AUC  F1 Score  \\\n0  GradientBoosting       0.826018      0.018962  0.87225   0.75969   \n\n   Precision    Recall  \n0   0.808581  0.716374  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy Mean</th>\n      <th>Accuracy Std</th>\n      <th>AUC</th>\n      <th>F1 Score</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GradientBoosting</td>\n      <td>0.826018</td>\n      <td>0.018962</td>\n      <td>0.87225</td>\n      <td>0.75969</td>\n      <td>0.808581</td>\n      <td>0.716374</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"#### Kaggle score highest from the ensemble (boosting) 78.9% (83 features)","metadata":{}},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}},{"cell_type":"markdown","source":"Best Parameters: {'classifier__ccp_alpha': 0.0, 'classifier__learning_rate': 0.01, 'classifier__loss': 'log_loss', 'classifier__max_depth': 5, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200, 'classifier__subsample': 1.0}","metadata":{}},{"cell_type":"code","source":"model_gb_2 = Pipeline([\n    # Uncomment the scaler if features are not tree-based categorical\n    # ('scaler', StandardScaler()),  \n    ('classifier', GradientBoostingClassifier(\n        loss='log_loss',           # Logistic loss for classification\n        learning_rate=0.01,         # Typical starting value\n        n_estimators=200,          # Number of boosting stages\n        subsample=1.0,             # No subsampling by default\n        min_samples_split=2,\n        min_samples_leaf=1,\n        max_depth=5,               # Control model complexity\n        max_features='sqrt',         # Can be 'sqrt' or 'log2'\n        random_state=42,\n        ccp_alpha=0.0              # No cost complexity pruning by default\n    ))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:53:54.164337Z","iopub.execute_input":"2025-05-12T23:53:54.164627Z","iopub.status.idle":"2025-05-12T23:53:54.169240Z","shell.execute_reply.started":"2025-05-12T23:53:54.164607Z","shell.execute_reply":"2025-05-12T23:53:54.168489Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"%%time\n#1.5s\ntrain_and_predict(\n    model=model_gb_2, # Tweak to find the best model and try other ml models\n    X_train=X_train_reduced_1, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test_reduced_1, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_gb_2.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T23:54:15.085145Z","iopub.execute_input":"2025-05-12T23:54:15.085383Z","iopub.status.idle":"2025-05-12T23:54:16.527901Z","shell.execute_reply.started":"2025-05-12T23:54:15.085367Z","shell.execute_reply":"2025-05-12T23:54:16.527121Z"}},"outputs":[{"name":"stdout","text":"Cross-validation scores: [0.82122905 0.80898876 0.83707865 0.82022472 0.85393258]\nMean cross-validation score: 0.8282907538760906\nSubmission saved to submit_gb_2.csv\nCPU times: user 1.44 s, sys: 0 ns, total: 1.44 s\nWall time: 1.44 s\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"#### Kaggle score  78.2% (17 features)","metadata":{}},{"cell_type":"markdown","source":"#### XG Boosting","metadata":{}},{"cell_type":"code","source":"def model_xgb_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False):\n    \"\"\"\n    Performs hyperparameter tuning for XGBClassifier using GridSearchCV.\n\n    Parameters:\n        X_train (pd.DataFrame): Training features.\n        y_train (pd.Series or np.array): Training target.\n        cv (int): Number of cross-validation folds (default is 5).\n        scoring (str): Scoring metric (default is 'accuracy').\n        use_sample_weight (bool): Whether to apply sample_weight as 'balanced'.\n\n    Returns:\n        GridSearchCV object (fitted)\n    \"\"\"\n    \n    # Compute sample weights if specified\n    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train) if use_sample_weight else None\n\n    # Define pipeline\n    pipe_xgb = Pipeline([\n        ('classifier', XGBClassifier(\n            objective='binary:logistic',\n            use_label_encoder=False,\n            eval_metric='logloss',\n            random_state=42\n        ))\n    ])\n\n    # Define parameter grid\n    param_grid = {\n        'classifier__learning_rate': [0.01, 0.1],\n        'classifier__n_estimators': [100, 200],\n        'classifier__max_depth': [3, 5, 7],\n        'classifier__subsample': [0.8, 1.0],\n        'classifier__colsample_bytree': [0.8, 1.0],\n        'classifier__gamma': [0, 1],\n        'classifier__reg_alpha': [0, 0.1],\n        'classifier__reg_lambda': [1, 10],\n        'classifier__scale_pos_weight': [1]  # could be tuned if dataset is imbalanced\n    }\n\n    # Define GridSearchCV\n    grid_search = GridSearchCV(\n        pipe_xgb,\n        param_grid,\n        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n        scoring=scoring,\n        n_jobs=-1,\n        verbose=1\n    )\n\n    # Fit model with or without sample_weight\n    if use_sample_weight:\n        grid_search.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n    else:\n        grid_search.fit(X_train, y_train)\n\n    print(\"Best Parameters:\", grid_search.best_params_)\n    print(f\"Best {scoring.capitalize()} Score: {grid_search.best_score_:.4f}\")\n\n    return grid_search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:01:55.295318Z","iopub.execute_input":"2025-05-13T00:01:55.296309Z","iopub.status.idle":"2025-05-13T00:01:55.302485Z","shell.execute_reply.started":"2025-05-13T00:01:55.296283Z","shell.execute_reply":"2025-05-13T00:01:55.301798Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"%%time\n#1 min 48s\nmodel_xgb_1 = model_xgb_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:01:55.303118Z","iopub.execute_input":"2025-05-13T00:01:55.303299Z","iopub.status.idle":"2025-05-13T00:02:58.826835Z","shell.execute_reply.started":"2025-05-13T00:01:55.303280Z","shell.execute_reply":"2025-05-13T00:02:58.825852Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 384 candidates, totalling 1920 fits\nBest Parameters: {'classifier__colsample_bytree': 1.0, 'classifier__gamma': 1, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 7, 'classifier__n_estimators': 200, 'classifier__reg_alpha': 0.1, 'classifier__reg_lambda': 1, 'classifier__scale_pos_weight': 1, 'classifier__subsample': 1.0}\nBest Accuracy Score: 0.8485\nCPU times: user 3.51 s, sys: 214 ms, total: 3.72 s\nWall time: 1min 3s\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Save to file after fitting\ndump(model_xgb_1, 'model_xgb_1.joblib')\nmodel_xgb_1.best_estimator_\n\n# Load it later when needed\n#grid_loaded = load('/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_gb_1.joblib')\n\n# Access best estimator\n#model_gb_1 = grid_loaded.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:02:58.828428Z","iopub.execute_input":"2025-05-13T00:02:58.828624Z","iopub.status.idle":"2025-05-13T00:02:58.857508Z","shell.execute_reply.started":"2025-05-13T00:02:58.828611Z","shell.execute_reply":"2025-05-13T00:02:58.856779Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('classifier',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=1.0, device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric='logloss',\n                               feature_types=None, gamma=1, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.01,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=7, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=200, n_jobs=None,\n                               num_parallel_tree=None, random_state=42, ...))])","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=1.0, device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n                               feature_types=None, gamma=1, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.01,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=7, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=200, n_jobs=None,\n                               num_parallel_tree=None, random_state=42, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=1.0, device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n                               feature_types=None, gamma=1, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.01,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=7, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=200, n_jobs=None,\n                               num_parallel_tree=None, random_state=42, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=1, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"%%time\n#11 min 44s\ntrain_and_predict(\n    model=model_xgb_1, # Tweak to find the best model and try other ml models\n    X_train=X_train, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_xgb_1.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:02:58.858243Z","iopub.execute_input":"2025-05-13T00:02:58.858449Z","iopub.status.idle":"2025-05-13T00:10:00.086890Z","shell.execute_reply.started":"2025-05-13T00:02:58.858431Z","shell.execute_reply":"2025-05-13T00:10:00.086156Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nCross-validation scores: [0.83798883 0.80337079 0.82022472 0.82022472 0.83707865]\nMean cross-validation score: 0.8237775406440274\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nSubmission saved to submit_xgb_1.csv\nCPU times: user 24.1 s, sys: 1.3 s, total: 25.4 s\nWall time: 7min 1s\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"%%time\n# Define your model list\nmodels = [\n    ('GradientBoosting', model_xgb_1),\n    # Add more models if needed\n]\n\n# Get the metrics DataFrame\nmetrics_df = compute_metrics_df(models, X_train, y_train, cv=5)\nmetrics_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:10:00.087531Z","iopub.execute_input":"2025-05-13T00:10:00.087732Z","iopub.status.idle":"2025-05-13T00:24:39.736162Z","shell.execute_reply.started":"2025-05-13T00:10:00.087718Z","shell.execute_reply":"2025-05-13T00:24:39.735514Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nCPU times: user 50.6 s, sys: 2.66 s, total: 53.3 s\nWall time: 14min 39s\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"              Model  Accuracy Mean  Accuracy Std       AUC  F1 Score  \\\n0  GradientBoosting       0.823778      0.012811  0.872144  0.754304   \n\n   Precision    Recall  \n0   0.811448  0.704678  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy Mean</th>\n      <th>Accuracy Std</th>\n      <th>AUC</th>\n      <th>F1 Score</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GradientBoosting</td>\n      <td>0.823778</td>\n      <td>0.012811</td>\n      <td>0.872144</td>\n      <td>0.754304</td>\n      <td>0.811448</td>\n      <td>0.704678</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"markdown","source":"#### Kaggle score 76.8%","metadata":{}},{"cell_type":"code","source":"%%time\nmodel_xgb_2 = Pipeline([\n    # Uncomment the scaler if features are not tree-based categorical\n    # ('scaler', StandardScaler()),  \n    ('classifier', XGBClassifier(\n        objective='binary:logistic',     # For binary classification\n        eval_metric='logloss',           # To match log-loss used in GradientBoosting\n        learning_rate=0.1,\n        n_estimators=100,\n        max_depth=5,\n        subsample=0.8,\n        colsample_bytree=1.0,\n        gamma=0,\n        reg_alpha=0.1,\n        reg_lambda=10,\n        scale_pos_weight=1,              # Adjust for class imbalance if needed\n        use_label_encoder=False,\n        random_state=42\n    ))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:24:39.736804Z","iopub.execute_input":"2025-05-13T00:24:39.736995Z","iopub.status.idle":"2025-05-13T00:24:39.741600Z","shell.execute_reply.started":"2025-05-13T00:24:39.736979Z","shell.execute_reply":"2025-05-13T00:24:39.740799Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 30 ¬µs, sys: 2 ¬µs, total: 32 ¬µs\nWall time: 34.8 ¬µs\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"%%time\n#1.5s\ntrain_and_predict(\n    model=model_xgb_2, # Tweak to find the best model and try other ml models\n    X_train=X_train_reduced_1, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test_reduced_1, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_xgb_2.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:24:39.743514Z","iopub.execute_input":"2025-05-13T00:24:39.743751Z","iopub.status.idle":"2025-05-13T00:24:40.050363Z","shell.execute_reply.started":"2025-05-13T00:24:39.743735Z","shell.execute_reply":"2025-05-13T00:24:40.049633Z"}},"outputs":[{"name":"stdout","text":"Cross-validation scores: [0.82122905 0.82022472 0.83707865 0.8258427  0.83707865]\nMean cross-validation score: 0.8282907538760907\nSubmission saved to submit_xgb_2.csv\nCPU times: user 554 ms, sys: 22.7 ms, total: 576 ms\nWall time: 289 ms\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"#### Kaggle score 76.3%\n\n#### Voting Classifier","metadata":{}},{"cell_type":"code","source":"# Define the voting classifier\nmodel_vot_1 = VotingClassifier(\n    estimators=[\n        ('log_reg', model_log_1),\n        ('gb', model_gb_1),\n        ('xgb', model_xgb_1)\n    ],\n    voting='soft'  # Use 'soft' for probabilities or 'hard' for majority voting\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:24:40.051036Z","iopub.execute_input":"2025-05-13T00:24:40.051243Z","iopub.status.idle":"2025-05-13T00:24:40.055083Z","shell.execute_reply.started":"2025-05-13T00:24:40.051226Z","shell.execute_reply":"2025-05-13T00:24:40.054159Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"%%time\n#10min 49s\ntrain_and_predict(\n    model=model_vot_1, # Tweak to find the best model and try other ml models\n    X_train=X_train, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_vot_1.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:24:40.055996Z","iopub.execute_input":"2025-05-13T00:24:40.056267Z","iopub.status.idle":"2025-05-13T00:35:29.492511Z","shell.execute_reply.started":"2025-05-13T00:24:40.056243Z","shell.execute_reply":"2025-05-13T00:35:29.491936Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nCross-validation scores: [0.83240223 0.82022472 0.82022472 0.80898876 0.83146067]\nMean cross-validation score: 0.8226602222082731\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 128 candidates, totalling 640 fits\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\nSubmission saved to submit_vot_1.csv\nCPU times: user 33.1 s, sys: 1.64 s, total: 34.8 s\nWall time: 10min 49s\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"#### Kaggle score 77.8%","metadata":{}},{"cell_type":"markdown","source":"#### KNN","metadata":{}},{"cell_type":"code","source":"def model_knn_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False):\n    \"\"\"\n    Performs hyperparameter tuning for KNeighborsClassifier using GridSearchCV.\n\n    Parameters:\n        X_train (pd.DataFrame): Training features.\n        y_train (pd.Series or np.array): Training target.\n        cv (int): Number of cross-validation folds (default is 5).\n        scoring (str): Scoring metric (default is 'accuracy').\n        use_sample_weight (bool): Whether to apply sample_weight as 'balanced'.\n\n    Returns:\n        GridSearchCV object (fitted)\n    \"\"\"\n\n    # Compute sample weights if specified (not used in KNN but included for consistency)\n    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train) if use_sample_weight else None\n\n    # Define pipeline\n    pipe_knn = Pipeline([\n        ('classifier', KNeighborsClassifier())\n    ])\n\n    # Define parameter grid for tuning\n    param_grid = {\n        'classifier__n_neighbors': [3, 5, 7, 9],\n        'classifier__weights': ['uniform', 'distance'],\n        'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree'],\n        'classifier__leaf_size': [20, 30, 40],\n        'classifier__p': [1, 2],  # 1=Manhattan, 2=Euclidean\n        'classifier__metric': ['minkowski']\n    }\n\n    # Define GridSearchCV\n    grid_search = GridSearchCV(\n        pipe_knn,\n        param_grid,\n        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n        scoring=scoring,\n        n_jobs=-1,\n        verbose=1\n    )\n\n    # Fit model (sample_weight not used here; sklearn raises warning if passed to KNN)\n    grid_search.fit(X_train, y_train)\n\n    print(\"Best Parameters:\", grid_search.best_params_)\n    print(f\"Best {scoring.capitalize()} Score: {grid_search.best_score_:.4f}\")\n\n    return grid_search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:37:36.497892Z","iopub.execute_input":"2025-05-13T00:37:36.498134Z","iopub.status.idle":"2025-05-13T00:37:36.504516Z","shell.execute_reply.started":"2025-05-13T00:37:36.498118Z","shell.execute_reply":"2025-05-13T00:37:36.503608Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"%%time\n#1 min 48s\nmodel_knn_1 = model_knn_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:38:28.331415Z","iopub.execute_input":"2025-05-13T00:38:28.332403Z","iopub.status.idle":"2025-05-13T00:38:32.430724Z","shell.execute_reply.started":"2025-05-13T00:38:28.332361Z","shell.execute_reply":"2025-05-13T00:38:32.429963Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 144 candidates, totalling 720 fits\nBest Parameters: {'classifier__algorithm': 'ball_tree', 'classifier__leaf_size': 30, 'classifier__metric': 'minkowski', 'classifier__n_neighbors': 7, 'classifier__p': 1, 'classifier__weights': 'uniform'}\nBest Accuracy Score: 0.8036\nCPU times: user 338 ms, sys: 18.9 ms, total: 356 ms\nWall time: 4.09 s\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"# Save to file after fitting\n#dump(model_knn_1, 'model_knn_1.joblib')\n#model_knn_1.best_estimator_\n\n# Load it later when needed\ngrid_loaded = load('/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_knn_1.joblib')\n\n# Access best estimator\nmodel_knn_1 = grid_loaded.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:02:09.504006Z","iopub.execute_input":"2025-05-13T01:02:09.504290Z","iopub.status.idle":"2025-05-13T01:02:15.640902Z","shell.execute_reply.started":"2025-05-13T01:02:09.504271Z","shell.execute_reply":"2025-05-13T01:02:15.639976Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 144 candidates, totalling 720 fits\nBest Parameters: {'classifier__algorithm': 'ball_tree', 'classifier__leaf_size': 30, 'classifier__metric': 'minkowski', 'classifier__n_neighbors': 7, 'classifier__p': 1, 'classifier__weights': 'uniform'}\nBest Accuracy Score: 0.8036\nCPU times: user 486 ms, sys: 36.1 ms, total: 522 ms\nWall time: 6.13 s\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('classifier',\n                 KNeighborsClassifier(algorithm='ball_tree', n_neighbors=7,\n                                      p=1))])","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 KNeighborsClassifier(algorithm=&#x27;ball_tree&#x27;, n_neighbors=7,\n                                      p=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 KNeighborsClassifier(algorithm=&#x27;ball_tree&#x27;, n_neighbors=7,\n                                      p=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(algorithm=&#x27;ball_tree&#x27;, n_neighbors=7, p=1)</pre></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"%%time\n#11 min 44s\ntrain_and_predict(\n    model=model_knn_1, # Tweak to find the best model and try other ml models\n    X_train=X_train, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_knn_1.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:50:37.527320Z","iopub.execute_input":"2025-05-13T00:50:37.527641Z","iopub.status.idle":"2025-05-13T00:51:04.828676Z","shell.execute_reply.started":"2025-05-13T00:50:37.527620Z","shell.execute_reply":"2025-05-13T00:51:04.827684Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nCross-validation scores: [0.74860335 0.81460674 0.79775281 0.80337079 0.82022472]\nMean cross-validation score: 0.7969116816270165\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nSubmission saved to submit_knn_1.csv\nCPU times: user 2.83 s, sys: 114 ms, total: 2.94 s\nWall time: 27.3 s\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"%%time\n# Define your model list\nmodels = [\n    ('KNN', model_knn_1),\n    # Add more models if needed\n]\n\n# Get the metrics DataFrame\nmetrics_df = compute_metrics_df(models, X_train, y_train, cv=5)\nmetrics_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:41:50.263107Z","iopub.execute_input":"2025-05-13T00:41:50.263327Z","iopub.status.idle":"2025-05-13T00:42:40.608809Z","shell.execute_reply.started":"2025-05-13T00:41:50.263314Z","shell.execute_reply":"2025-05-13T00:42:40.608259Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nFitting 5 folds for each of 144 candidates, totalling 720 fits\nCPU times: user 5.36 s, sys: 221 ms, total: 5.58 s\nWall time: 50.3 s\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"  Model  Accuracy Mean  Accuracy Std       AUC  F1 Score  Precision    Recall\n0   KNN       0.796912      0.025427  0.836622   0.70947   0.786477  0.646199","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy Mean</th>\n      <th>Accuracy Std</th>\n      <th>AUC</th>\n      <th>F1 Score</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNN</td>\n      <td>0.796912</td>\n      <td>0.025427</td>\n      <td>0.836622</td>\n      <td>0.70947</td>\n      <td>0.786477</td>\n      <td>0.646199</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"%%time\nmodel_knn_2 = Pipeline([\n    # Uncomment the scaler if features are not tree-based categorical\n    # ('scaler', StandardScaler()),  \n    ('classifier', KNeighborsClassifier(\n        weights='uniform',\n        algorithm='ball_tree',\n        leaf_size=30,\n        metric='minkowski',\n        n_neighbors=7,\n        p=1\n    ))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:49:31.342424Z","iopub.execute_input":"2025-05-13T00:49:31.342717Z","iopub.status.idle":"2025-05-13T00:49:31.347860Z","shell.execute_reply.started":"2025-05-13T00:49:31.342701Z","shell.execute_reply":"2025-05-13T00:49:31.346935Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 13 ¬µs, sys: 1 ¬µs, total: 14 ¬µs\nWall time: 17.9 ¬µs\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"Best Parameters: {'classifier__algorithm': 'ball_tree', 'classifier__leaf_size': 30, 'classifier__metric': 'minkowski', 'classifier__n_neighbors': 7, 'classifier__p': 1, 'classifier__weights': 'uniform'}","metadata":{}},{"cell_type":"code","source":"%%time\n#11 min 44s\ntrain_and_predict(\n    model=model_knn_2, # Tweak to find the best model and try other ml models\n    X_train=X_train_reduced_1, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test_reduced_1, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_knn_2.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T00:51:04.829894Z","iopub.execute_input":"2025-05-13T00:51:04.830178Z","iopub.status.idle":"2025-05-13T00:51:04.906360Z","shell.execute_reply.started":"2025-05-13T00:51:04.830159Z","shell.execute_reply":"2025-05-13T00:51:04.905429Z"}},"outputs":[{"name":"stdout","text":"Cross-validation scores: [0.77094972 0.80337079 0.76404494 0.8258427  0.85393258]\nMean cross-validation score: 0.8036281463812692\nSubmission saved to submit_knn_2.csv\nCPU times: user 68 ms, sys: 6.05 ms, total: 74.1 ms\nWall time: 71.7 ms\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"#### Kaggle score 74.6%","metadata":{}},{"cell_type":"markdown","source":"#### AdaBoosting ","metadata":{}},{"cell_type":"code","source":"def model_ab_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False):\n    \"\"\"\n    Performs hyperparameter tuning for AdaBoostClassifier using GridSearchCV.\n\n    Parameters:\n        X_train (pd.DataFrame): Training features.\n        y_train (pd.Series or np.array): Training target.\n        cv (int): Number of cross-validation folds (default is 5).\n        scoring (str): Scoring metric (default is 'accuracy').\n        use_sample_weight (bool): Whether to apply sample_weight as 'balanced'.\n\n    Returns:\n        GridSearchCV object (fitted)\n    \"\"\"\n\n    # Compute sample weights if specified\n    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train) if use_sample_weight else None\n\n    # Define base estimator for AdaBoost\n    base_estimator = DecisionTreeClassifier(random_state=42)\n\n    # Define pipeline\n    pipe_ada = Pipeline([\n        ('classifier', AdaBoostClassifier(estimator=base_estimator, random_state=42))\n    ])\n\n    # Expanded parameter grid\n    param_grid = {\n        'classifier__n_estimators': [50, 100, 200, 300],\n        'classifier__learning_rate': [0.001, 0.01, 0.1, 0.5, 1.0],\n        'classifier__estimator__max_depth': [1, 2, 3, 4, 5],\n        'classifier__estimator__min_samples_split': [2, 5, 10],\n        'classifier__estimator__min_samples_leaf': [1, 2, 4],\n        'classifier__estimator__max_features': [None, 'sqrt', 'log2']\n    }\n\n    # Define GridSearchCV\n    grid_search = GridSearchCV(\n        pipe_ada,\n        param_grid,\n        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n        scoring=scoring,\n        n_jobs=-1,\n        verbose=1\n    )\n\n    # Fit model\n    if use_sample_weight:\n        grid_search.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n    else:\n        grid_search.fit(X_train, y_train)\n\n    print(\"Best Parameters:\", grid_search.best_params_)\n    print(f\"Best {scoring.capitalize()} Score: {grid_search.best_score_:.4f}\")\n\n    return grid_search","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n#23 min 23s\nmodel_ab_1 = model_ab_selection(X_train, y_train, cv=5, scoring='accuracy', use_sample_weight=False)# Save to file after fitting\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:03:24.005635Z","iopub.execute_input":"2025-05-13T01:03:24.005904Z","iopub.status.idle":"2025-05-13T01:26:47.150955Z","shell.execute_reply.started":"2025-05-13T01:03:24.005885Z","shell.execute_reply":"2025-05-13T01:26:47.149782Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 2700 candidates, totalling 13500 fits\nBest Parameters: {'classifier__estimator__max_depth': 4, 'classifier__estimator__max_features': None, 'classifier__estimator__min_samples_leaf': 2, 'classifier__estimator__min_samples_split': 10, 'classifier__learning_rate': 0.01, 'classifier__n_estimators': 300}\nBest Accuracy Score: 0.8395\nCPU times: user 38.5 s, sys: 3.67 s, total: 42.1 s\nWall time: 23min 23s\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# Save to file after fitting\ndump(model_ab_1, 'model_ab_1.joblib')\nmodel_ab_1.best_estimator_\n\n# Load it later when needed\n#grid_loaded = load('/kaggle/input/task001-p03-ml-models/scikitlearn/default/1/model_ab_1.joblib')\n\n# Access best estimator\n#model_ab_1 = grid_loaded.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:28:10.822543Z","iopub.execute_input":"2025-05-13T01:28:10.822887Z","iopub.status.idle":"2025-05-13T01:28:10.955458Z","shell.execute_reply.started":"2025-05-13T01:28:10.822863Z","shell.execute_reply":"2025-05-13T01:28:10.954558Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('classifier',\n                 AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4,\n                                                                     min_samples_leaf=2,\n                                                                     min_samples_split=10,\n                                                                     random_state=42),\n                                    learning_rate=0.01, n_estimators=300,\n                                    random_state=42))])","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4,\n                                                                     min_samples_leaf=2,\n                                                                     min_samples_split=10,\n                                                                     random_state=42),\n                                    learning_rate=0.01, n_estimators=300,\n                                    random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n                 AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4,\n                                                                     min_samples_leaf=2,\n                                                                     min_samples_split=10,\n                                                                     random_state=42),\n                                    learning_rate=0.01, n_estimators=300,\n                                    random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4,\n                                                    min_samples_leaf=2,\n                                                    min_samples_split=10,\n                                                    random_state=42),\n                   learning_rate=0.01, n_estimators=300, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, min_samples_leaf=2, min_samples_split=10,\n                       random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, min_samples_leaf=2, min_samples_split=10,\n                       random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"%%time\n#11 min 44s\ntrain_and_predict(\n    model=model_ab_1, # Tweak to find the best model and try other ml models\n    X_train=X_train, # Tweak the features (e.g. add feature engineering or drop feature(s), features importance )\n    y_train=y_train,\n    X_test=X_test, # follow the changes in X_train\n    test_ids=df[891:]['PassengerId'],\n    cv=5, # Tweak the cv\n    submission_name='submit_ab_1.csv'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:31:36.804308Z","iopub.execute_input":"2025-05-13T01:31:36.804604Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 2700 candidates, totalling 13500 fits\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"#### Kaggle score 77.8%","metadata":{}},{"cell_type":"markdown","source":"#### The highest boosting still from Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}},{"cell_type":"markdown","source":"<img style=\"float:left\" src=\"https://i.imgur.com/wpcEXQC.png\" width=\"50\"><div style = \"font-family: Arial; font-size: 16px\">\n    <h1>Execute - share</h1></div>","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, HTML\n# Link HTML files for pages\noutput_file_02 = \"https://www.kaggle.com/code/wahyuardhitama/proj005-p02-abc-20250802\"\noutput_file_03 = \"https://www.kaggle.com/code/wahyuardhitama/proj005-p03-nyc-xyz-20250824\"\n\n# Display links to the saved HTML files\ndisplay(HTML(f\"<p style='font-size: 18px;'>Go to <a href='{output_file_02}' target='_blank' style='font-size: 18px;'>P02 </a>or go to <a href='{output_file_03}' target='_blank' style='font-size: 18px;'>P03 </a></p>\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1><a id=\"Ex\">Summary</a></h1>  \n\nWe have built classification models to predict categorical course ratings using the embedding feature vectors extracted from neural networks.\n<hr>\n\n<div class=\"alert alert-block alert-success\" style=\"font-family:verdana; font-size:14px\">\n<ol>The classification models to predict categorical course ratings using the embedding feature vectors extracted from neural networks filtering results\n    <li>Provide insights into which features contribute to a specific rating class.\n    <li>Easier to understand the distinctions between various user preferences.\n    <li>Classification is well-suited for scenarios where the ratings are discrete and categorical, such as a system where users provide ratings on a scale (e.g., 1 to 5 stars).\n</ol>","metadata":{}},{"cell_type":"markdown","source":"[go to top](#top)  ","metadata":{}}]}